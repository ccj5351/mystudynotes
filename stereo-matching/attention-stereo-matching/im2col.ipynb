{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# im2col opration in Pytorch\n",
    "> see [How to keep the shape of input and output same when dilation conv?](https://discuss.pytorch.org/t/how-to-keep-the-shape-of-input-and-output-same-when-dilation-conv/14338)  \n",
    "> see convolution visulization at https://ezyang.github.io/convolution-visualizer/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to keep the shape of input and output same when dilation conv?\n",
    "> see https://discuss.pytorch.org/t/how-to-keep-the-shape-of-input-and-output-same-when-dilation-conv/14338  \n",
    "\n",
    "Given:\n",
    "- o = output\n",
    "- p = padding\n",
    "- k = kernel_size\n",
    "- s = stride\n",
    "- d = dilation\n",
    "\n",
    "To get output:\n",
    " $$o = [i + 2p - k - (k-1)*(d-1)]/s + 1$$\n",
    "\n",
    "If we want the `same` size, and with $s = 1$, $k = 3$ in our project here, then we can get:  \n",
    "\n",
    "==>  $o = i = i + 2p - 3 - 2(d-1) + 1$   \n",
    "==>  $2p - 3 - 2d + 2 + 1 = 0$  \n",
    "==>  $2p - 2d = 0$  \n",
    "==>  $p = d$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2col in PyTorch via torch.nn.Unfold\n",
    "\n",
    "PyTorch im2col (i.e., `nn.Unfold`) flattens each $k \\times k$ block into a column which conains $C*(k*k)$ values, where $k*k$ is a continugous chunk, with $C$ be the Channel dimension. That means we can reshape the $C*(k*k)$ elements to $C \\times (k*k)$,  instead of $(k*k) \\times C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: \n",
    "In this example, $C = 1$, so I made a wrong conclusion: to reshape $C*(k*k)$ elements to $(k*k) \\times C$. Because $C=1$, so that is no differece between $1*(k*k) \\rightarrow (k*k) \\times 1$  and $1*(k*k) \\rightarrow 1 \\times (k*k)$, w.r.t. matrix element indexing (in memory). For example, x in shape $[N,C,H,W] = [2,1,9,9]$, and kernel size $k = 3$. So the im2col result has the shape $[N, C*k*k, H, W] = [2,1*3*3,9,9]$, you can reshape it to $[N, 1,k*k, H,W]$ or $[N, k*k, 1, H,W]$, and this is no difference for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1415,  0.9311, -0.4274],\n",
      "        [-1.9487, -0.6907, -0.0047],\n",
      "        [ 0.3701, -1.3672,  0.5315]], device='cuda:0')\n",
      "tensor([-0.1415,  0.9311, -0.4274, -1.9487, -0.6907, -0.0047,  0.3701, -1.3672,\n",
      "         0.5315], device='cuda:0')\n",
      "torch.Size([2, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "unfold = nn.Unfold(kernel_size=(3, 3), dilation = 1, padding = 1, stride = 1)\n",
    "x = torch.randn(2, 1, 9, 9)\n",
    "x = x.to(device)\n",
    "h,w = x.size()[2:4]\n",
    "print (x[0,0,4:7,2:5])\n",
    "y = unfold(x)\n",
    "y = y.view(y.size(0), y.size(1), h, w)\n",
    "print (y[0,:,5,3])\n",
    "# each patch contains 30 values (2x3=6 vectors, each of \n",
    "#5 channels) \n",
    "# 4 blocks (2x3 kernels) in total in the 3x4 input\n",
    "print (y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: \n",
    "In this example, $C = 3$, so I found the final correct conclusion: to reshape $C*(k*k)$ elements to $C \\times (k*k)$, using this example. Note that $k*k$ is a continugous chunk in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding =  1\n",
      "x[0,c=0,4:7,2:5] =\n",
      " tensor([[ 0.4197, -0.3778, -0.0688],\n",
      "        [-0.1916, -1.2742, -0.6662],\n",
      "        [-0.3673,  1.0866, -1.7710]], device='cuda:0')\n",
      "x[0,c=1,4:7,2:5] =\n",
      " tensor([[-0.6965,  0.7519,  0.7451],\n",
      "        [-0.9081,  0.0528, -0.5768],\n",
      "        [-0.7495,  0.9167,  0.8326]], device='cuda:0')\n",
      "x[0,c=2,4:7,2:5] =\n",
      " tensor([[-1.3579,  1.5046,  2.3742],\n",
      "        [-0.0505,  0.5745,  0.6749],\n",
      "        [-0.6443, -0.4178, -0.6896]], device='cuda:0')\n",
      "Reshape to 4D: y[0,:,5,3] =\n",
      " tensor([ 0.4197, -0.3778, -0.0688, -0.1916, -1.2742, -0.6662, -0.3673,  1.0866,\n",
      "        -1.7710, -0.6965,  0.7519,  0.7451, -0.9081,  0.0528, -0.5768, -0.7495,\n",
      "         0.9167,  0.8326, -1.3579,  1.5046,  2.3742, -0.0505,  0.5745,  0.6749,\n",
      "        -0.6443, -0.4178, -0.6896], device='cuda:0')\n",
      "Reshape to 5D, y[0,c=0,:,5,3] =\n",
      " tensor([ 0.4197, -0.3778, -0.0688, -0.1916, -1.2742, -0.6662, -0.3673,  1.0866,\n",
      "        -1.7710], device='cuda:0')\n",
      "y[0,c=1,:,5,3] =\n",
      " tensor([-0.6965,  0.7519,  0.7451, -0.9081,  0.0528, -0.5768, -0.7495,  0.9167,\n",
      "         0.8326], device='cuda:0')\n",
      "y[0,c=2,:,5,3] =\n",
      " tensor([-1.3579,  1.5046,  2.3742, -0.0505,  0.5745,  0.6749, -0.6443, -0.4178,\n",
      "        -0.6896], device='cuda:0')\n",
      "torch.Size([2, 3, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "k = 3\n",
    "p = k//2\n",
    "print ('padding = ', p)\n",
    "unfold = nn.Unfold(kernel_size=(3, 3), dilation = 1, padding = p, stride = 1)\n",
    "x = torch.randn(2, 3, 9, 9)\n",
    "x = x.to(device)\n",
    "N,C,H,W = x.size()[:]\n",
    "print ('x[0,c=0,4:7,2:5] =\\n', x[0,0,4:7,2:5])\n",
    "print ('x[0,c=1,4:7,2:5] =\\n', x[0,1,4:7,2:5])\n",
    "print ('x[0,c=2,4:7,2:5] =\\n', x[0,2,4:7,2:5])\n",
    "\n",
    "y0 = unfold(x) # in size NxC*k*kxHxW\n",
    "y = y0.view(N, C*k*k, H, W)\n",
    "print ('Reshape to 4D: y[0,:,5,3] =\\n', y[0,:,5,3])\n",
    "\n",
    "y = y0.view(N, C, k*k, H, W)\n",
    "print ('Reshape to 5D, y[0,c=0,:,5,3] =\\n', y[0,0,:,5,3])\n",
    "print ('y[0,c=1,:,5,3] =\\n', y[0,1,:,5,3])\n",
    "print ('y[0,c=2,:,5,3] =\\n', y[0,2,:,5,3])\n",
    "# each patch contains 30 values (2x3=6 vectors, each of \n",
    "#5 channels) \n",
    "# 4 blocks (2x3 kernels) in total in the 3x4 input\n",
    "print (y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
