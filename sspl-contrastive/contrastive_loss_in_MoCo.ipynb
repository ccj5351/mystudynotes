{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745e79d6-c4a3-45d9-9e5e-66292461dec0",
   "metadata": {},
   "source": [
    "# Contrastive Losse in MoCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a14b5-b444-4053-b959-333bef69cbda",
   "metadata": {},
   "source": [
    "## Constrastive Loss\n",
    "\n",
    "> We cite the texts from [MoCo v3](https://arxiv.org/pdf/2104.02057.pdf)\n",
    "\n",
    "> As common practice (e.g., [20, 10]), we take two crops for each image under random data augmentation. They are encoded by two encoders, $f_q$ and $f_k$, with output vectors $q$ and $k$. Intuitively, $q$ behaves like a “query” [20], and the goal of learning is to retrieve the corresponding “key”. This is formulated as minimizing a contrastive loss function [19]. We adopt the form of InfoNCE [34]:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{q}=-\\log \\frac{\\exp \\left(q \\cdot k^{+} / \\tau\\right)}{\\exp \\left(q \\cdot k^{+} / \\tau\\right)+\\sum_{k^{-}} \\exp \\left(q \\cdot k^{-} / \\tau\\right)}\n",
    "$$\n",
    "\n",
    "> Here $k_{+}$ is $f_k$’s output on the same image as $q$, known as $q$’s positive sample. The set $\\{k^{−}\\}$ consists of $f_k$’s outputs from other images, known as $q$’s negative samples. $\\tau$ is a temperature hyper-parameter [45] for $l_2$-normalized $q$, $k$.\n",
    "\n",
    "> Following [46, 22, 2, 10], in MoCo v3 we use the keys `that naturally co-exist in the same batch`. We abandon the memory queue [20], which we find has diminishing gain if the batch is sufficiently large (e.g., 4096). With this simplification, the contrastive loss in (1) can be implemented by a few lines of code: see `ctr(q, k)` in Alg. 1. We adopt a symmetrized loss [18, 7, 13]: `ctr(q1, k2)+ctr(q2, k1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce834d5-d55e-4f6f-a1d0-74596566c027",
   "metadata": {},
   "source": [
    "## Code Samples in MoCo v3\n",
    "\n",
    "### Contrastive loss\n",
    "\n",
    "```python\n",
    "def contrastive_loss(self, q, k):\n",
    "        # normalize\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        k = nn.functional.normalize(k, dim=1)\n",
    "        # gather all targets\n",
    "        k = concat_all_gather(k)\n",
    "        # Einstein sum is more intuitive\n",
    "        logits = torch.einsum('nc,mc->nm', [q, k]) / self.T\n",
    "        N = logits.shape[0]  # batch size per GPU\n",
    "        labels = (torch.arange(N, dtype=torch.long) + N * torch.distributed.get_rank()).cuda()\n",
    "        return nn.CrossEntropyLoss()(logits, labels) * (2 * self.T)\n",
    "\n",
    "```\n",
    "\n",
    "It requires the following function `concat_all_gather(tensor)` or `torch.distributed.all_gather()` more specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f0a605-7cf7-4fdb-8af8-b53e01dc4a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CCJ's Note: \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# > see: https://amsword.medium.com/gradient-backpropagation-with-torch-distributed-all-gather-9f3941a381f8\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Typically, each GPU can calculate the loss of g（x） and \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# utils:\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat_all_gather\u001b[39m(tensor):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Performs all_gather operation on the provided tensors.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    *** Warning ***: torch.distributed.all_gather has no gradient.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     tensors_gather \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mones_like(tensor)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mget_world_size())]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# CCJ's Note: \n",
    "# > see: https://amsword.medium.com/gradient-backpropagation-with-torch-distributed-all-gather-9f3941a381f8\n",
    "# Typically, each GPU can calculate the loss of g（x） and \n",
    "# then the auto grad will do the job to calculate the gradient for \n",
    "# all parameters. Normally, this is paired with DistributedDataParallel, \n",
    "# which will do the averaging automatically. In this case, we don’t need \n",
    "# to gather other GPU’s output. But, what if the loss is not separable?\n",
    "# This is why we use `torch.distributed.all_gather()`.\n",
    "\n",
    "# utils:\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    \n",
    "    # CCJ's Note: Gathers tensors from the whole group in a list.\n",
    "    # > see: https://pytorch.org/docs/stable/distributed.html#torch.distributed.all_gather\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac053d1-fec6-4afc-b159-af927e2e5454",
   "metadata": {},
   "source": [
    "## My Notes\n",
    "\n",
    "### Questions\n",
    "- 1) Why requires `torch.distributed.all_gather()`?\n",
    "- 2) How to understand and implement the statement that `in MoCo v3 we use the keys that naturally co-exist in the same batch`?\n",
    "\n",
    "### My Understanding\n",
    "\n",
    "- To collect all the keys (which are used as targets fed into the cross entroy loss function) from the whole group into a list. Since the contrastive loss is defined as query $q_i$ vs. all the keys (i.e., key $k_i$ among all the processes or GPUs $i$, where $i=0,1,2, \\dots , N-1$). \n",
    "\n",
    "- For example, we have two nodes (i.e., process groups), and each with 2 GPUs (with local rank $0, 1$), then the world size is $2*2=4$, and the global rank $0, 1, 2, 3$.\n",
    "\n",
    "- Syntax: torch.distributed.all_gather(tensor_list, tensor, group=None, async_op=False):\n",
    "\n",
    "```python\n",
    "# All tensors below are of torch.int64 dtype.\n",
    "# We have 2 process groups, 2 ranks.\n",
    "tensor_list = [torch.zeros(2, dtype=torch.int64) for _ in range(2)]\n",
    ">>> tensor_list\n",
    "[tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1\n",
    "\n",
    "tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank\n",
    ">>> tensor\n",
    "tensor([1, 2]) # Rank 0\n",
    "tensor([3, 4]) # Rank 1\n",
    "\n",
    "dist.all_gather(tensor_list, tensor)\n",
    ">>> tensor_list\n",
    "[tensor([1, 2]), tensor([3, 4])] # Rank 0\n",
    "[tensor([1, 2]), tensor([3, 4])] # Rank 1\n",
    "```\n",
    "\n",
    "- As for this contrastive loss:\n",
    "\n",
    "```python\n",
    "def contrastive_loss(self, q, k):\n",
    "        # normalize\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        k = nn.functional.normalize(k, dim=1)\n",
    "        # gather all targets\n",
    "        k = concat_all_gather(k)\n",
    "        # Einstein sum is more intuitive\n",
    "        logits = torch.einsum('nc,mc->nm', [q, k]) / self.T\n",
    "        N = logits.shape[0]  # batch size per GPU\n",
    "        labels = (torch.arange(N, dtype=torch.long) + N * torch.distributed.get_rank()).cuda()\n",
    "        return nn.CrossEntropyLoss()(logits, labels) * (2 * self.T)\n",
    "\n",
    "```\n",
    "\n",
    "where, pay attention to:\n",
    "\n",
    "``` python\n",
    "# gather all targets\n",
    "k = concat_all_gather(k) # calling torch.distributed.all_gather();\n",
    "```\n",
    "\n",
    "For convenience, just assuming batch size of $N=2$ for each GPU among those 4 GPUs. The current process, for example, is in GPU rank $2$, when we calculate the contrastive loss for query $q_2$ vs all the keys $\\{k_0, k_1, k_2, k_3\\}$, only $q_2$ and $k_2$ as a positive pair (SHOULD have samle label) due to coming from the same sample, and $q_2$ vs others keys as the negative pairs (SHOULD have different labels).\n",
    "\n",
    "With this \"nice\" design by specifying the labels with batch size $N$ and global rank, the query $q$ and key $k$ which co-exist in the same batch will have the same label, and hence as positive pair.\n",
    "\n",
    "```python\n",
    "# batch size N=2, world_size = 4, 2 nodes, each has 2 GPUs\n",
    "labels = (torch.arange(N, dtype=torch.long) + N * torch.distributed.get_rank()).cuda()\n",
    ">>> tensor_list\n",
    "[tensor([0, 1]), tensor([2, 3]), tensor([4, 5]), tensor([6, 7])] # Rank 0\n",
    "[tensor([0, 1]), tensor([2, 3]), tensor([4, 5]), tensor([6, 7])] # Rank 1\n",
    "[tensor([0, 1]), tensor([2, 3]), tensor([4, 5]), tensor([6, 7])] # Rank 2\n",
    "[tensor([0, 1]), tensor([2, 3]), tensor([4, 5]), tensor([6, 7])] # Rank 3\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29000c9b-48ac-4314-8b09-37955fb3b009",
   "metadata": {},
   "source": [
    "### Complete Code in MoCo v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a25eb3-a1c7-4041-8846-b558b1cf69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a MoCo model with a base encoder, a momentum encoder, and two MLPs\n",
    "    https://arxiv.org/abs/1911.05722\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, dim=256, mlp_dim=4096, T=1.0):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 256)\n",
    "        mlp_dim: hidden dimension in MLPs (default: 4096)\n",
    "        T: softmax temperature (default: 1.0)\n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.T = T\n",
    "\n",
    "        # build encoders\n",
    "        self.base_encoder = base_encoder(num_classes=mlp_dim)\n",
    "        self.momentum_encoder = base_encoder(num_classes=mlp_dim)\n",
    "\n",
    "        self._build_projector_and_predictor_mlps(dim, mlp_dim)\n",
    "\n",
    "        for param_b, param_m in zip(self.base_encoder.parameters(), self.momentum_encoder.parameters()):\n",
    "            param_m.data.copy_(param_b.data)  # initialize\n",
    "            param_m.requires_grad = False  # not update by gradient\n",
    "\n",
    "    def _build_mlp(self, num_layers, input_dim, mlp_dim, output_dim, last_bn=True):\n",
    "        mlp = []\n",
    "        for l in range(num_layers):\n",
    "            dim1 = input_dim if l == 0 else mlp_dim\n",
    "            dim2 = output_dim if l == num_layers - 1 else mlp_dim\n",
    "\n",
    "            mlp.append(nn.Linear(dim1, dim2, bias=False))\n",
    "\n",
    "            if l < num_layers - 1:\n",
    "                mlp.append(nn.BatchNorm1d(dim2))\n",
    "                mlp.append(nn.ReLU(inplace=True))\n",
    "            elif last_bn:\n",
    "                # follow SimCLR's design: https://github.com/google-research/simclr/blob/master/model_util.py#L157\n",
    "                # for simplicity, we further removed gamma in BN\n",
    "                mlp.append(nn.BatchNorm1d(dim2, affine=False))\n",
    "\n",
    "        return nn.Sequential(*mlp)\n",
    "\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _update_momentum_encoder(self, m):\n",
    "        \"\"\"Momentum update of the momentum encoder\"\"\"\n",
    "        for param_b, param_m in zip(self.base_encoder.parameters(), self.momentum_encoder.parameters()):\n",
    "            param_m.data = param_m.data * m + param_b.data * (1. - m)\n",
    "\n",
    "    def contrastive_loss(self, q, k):\n",
    "        # normalize\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        k = nn.functional.normalize(k, dim=1)\n",
    "        # gather all targets\n",
    "        k = concat_all_gather(k)\n",
    "        # Einstein sum is more intuitive\n",
    "        logits = torch.einsum('nc,mc->nm', [q, k]) / self.T\n",
    "        N = logits.shape[0]  # batch size per GPU\n",
    "        labels = (torch.arange(N, dtype=torch.long) + N * torch.distributed.get_rank()).cuda()\n",
    "        return nn.CrossEntropyLoss()(logits, labels) * (2 * self.T)\n",
    "\n",
    "    def forward(self, x1, x2, m):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x1: first views of images\n",
    "            x2: second views of images\n",
    "            m: moco momentum\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "\n",
    "        # compute features\n",
    "        q1 = self.predictor(self.base_encoder(x1))\n",
    "        q2 = self.predictor(self.base_encoder(x2))\n",
    "\n",
    "        with torch.no_grad():  # no gradient\n",
    "            self._update_momentum_encoder(m)  # update the momentum encoder\n",
    "\n",
    "            # compute momentum features as targets\n",
    "            # CCJ's Note: MoCo v3 used the keys that naturally co-exist \n",
    "            # in the same batch\n",
    "            k1 = self.momentum_encoder(x1)\n",
    "            k2 = self.momentum_encoder(x2)\n",
    "\n",
    "        return self.contrastive_loss(q1, k2) + self.contrastive_loss(q2, k1)\n",
    "\n",
    "\n",
    "class MoCo_ResNet(MoCo):\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        hidden_dim = self.base_encoder.fc.weight.shape[1]\n",
    "        del self.base_encoder.fc, self.momentum_encoder.fc # remove original fc layer\n",
    "\n",
    "        # projectors\n",
    "        self.base_encoder.fc = self._build_mlp(2, hidden_dim, mlp_dim, dim)\n",
    "        self.momentum_encoder.fc = self._build_mlp(2, hidden_dim, mlp_dim, dim)\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = self._build_mlp(2, dim, mlp_dim, dim, False)\n",
    "\n",
    "\n",
    "class MoCo_ViT(MoCo):\n",
    "    def _build_projector_and_predictor_mlps(self, dim, mlp_dim):\n",
    "        hidden_dim = self.base_encoder.head.weight.shape[1]\n",
    "        del self.base_encoder.head, self.momentum_encoder.head # remove original fc layer\n",
    "\n",
    "        # projectors\n",
    "        self.base_encoder.head = self._build_mlp(3, hidden_dim, mlp_dim, dim)\n",
    "        self.momentum_encoder.head = self._build_mlp(3, hidden_dim, mlp_dim, dim)\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = self._build_mlp(2, dim, mlp_dim, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18eae9-32d7-43fb-9970-e3ae40173a71",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
