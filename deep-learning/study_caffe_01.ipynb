{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Caffe 01 : 2019/02/23\n",
    "\n",
    "> blog 1: [Deep learning tutorial on Caffe technology : basic commands, Python and C++ code](http://christopher5106.github.io/deep/learning/2015/09/04/Deep-learning-tutorial-on-Caffe-Technology.html);  \n",
    "> blog 2: [A Practical Introduction to Deep Learning with Caffe and Python](http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a network model\n",
    "Let’s create first a very simple model with a single convolution composed of 3 convolutional neurons, with kernel of size 5x5 and stride of 1.  \n",
    "![exam1](http://christopher5106.github.io/img/simple_network.png)  \n",
    "\n",
    "This net will produce 3 output maps from an input map.\n",
    "\n",
    "The output map for a convolution given receptive field size has a dimension given by the following equation :  \n",
    "`output = (input - kernel_size) / stride + 1`\n",
    "\n",
    "Create a first file `conv.prototxt` describing the neuron network :\n",
    "\n",
    "```\n",
    "name: \"convolution\"\n",
    "input: \"data\"\n",
    "input_dim: 1\n",
    "input_dim: 100\n",
    "layer {\n",
    "  name: \"conv\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"data\"\n",
    "  top: \"conv\"\n",
    "  convolution_param {\n",
    "    num_output: 3\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"gaussian\"\n",
    "      std: 0.01\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "      value: 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "with one layer, a convolution, from the [Catalog of available layers](http://caffe.berkeleyvision.org/tutorial/layers.html)\n",
    "\n",
    "Load the net via  \n",
    "`net = caffe.Net('conv.prototxt', caffe.TEST)`  \n",
    "\n",
    "The names of input layers of the net are given by `print net.inputs`.\n",
    "\n",
    "The net contains two ordered dictionaries:\n",
    "\n",
    "- `net.blobs` for input data and its propagation in the layers:  \n",
    "`net.blobs['data']` contains input data, an array of shape (1, 1, 100, 100), `net.blobs['conv']` contains computed data in layer ‘conv’ (1, 3, 96, 96) initialiazed with zeros.\n",
    "\n",
    "To print the infos, `[(k, v.data.shape) for k, v in net.blobs.items()]`\n",
    "\n",
    "- `net.params` a vector of blobs for weight and bias parameters:  \n",
    "`net.params['conv'][0]` contains the weight parameters, an array of shape (3, 1, 5, 5)  \n",
    "`net.params['conv'][1]` contains the bias parameters, an array of shape (3,)  \n",
    "initialiazed with ‘weight_filler’ and ‘bias_filler’ algorithms.  \n",
    "To print the infos : `[(k, v[0].data.shape, v[1].data.shape) for k, v in net.params.items()]`\n",
    "\n",
    "Blobs are memory abstraction objects (with execution depending on the mode), and data is contained in the field data as an array:\n",
    "\n",
    "> print net.blobs['conv'].data.shape\n",
    "\n",
    "To draw the network, a simle python command:  \n",
    "> python python/draw_net.py examples/net_surgery/conv.prototxt my_net.png\n",
    "> open my_net.png\n",
    "\n",
    "This will print the following image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the net output on an image as input\n",
    "Let’s load a gray image of size 1x360x480 (channel x height x width) into the previous net:  \n",
    "![cat](http://christopher5106.github.io/img/cat_gray.jpg)\n",
    "\n",
    "We need to reshape the data blob (1, 1, 100, 100) to the new size (1, 1, 360, 480) to fit the image:\n",
    "\n",
    "```python\n",
    "im = np.array(Image.open('examples/images/cat_gray.jpg'))\n",
    "im_input = im[np.newaxis, np.newaxis, :, :]\n",
    "net.blobs['data'].reshape(*im_input.shape)\n",
    "net.blobs['data'].data[...] = im_input\n",
    "```\n",
    "Let’s compute the blobs given this input\n",
    "```python\n",
    "net.forward()\n",
    "```\n",
    "Now `net.blobs['conv']` is filled with data, and the 3 pictures inside each of the 3 neurons (`net.blobs['conv'].data[0,i]`) can be plotted easily.\n",
    "\n",
    "To save the net parameters `net.params`, just call :\n",
    "```python\n",
    "net.save('mymodel.caffemodel')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained parameters to classify an image\n",
    "\n",
    "In the previous net, weight and bias params have been initialiazed randomly.\n",
    "\n",
    "It is possible to load trained parameters and in this case, the result of the net will produce a classification.\n",
    "\n",
    "Many trained models can be downloaded from the community in the `Caffe Model Zoo`, such as car classification, flower classification, digit classification…\n",
    "\n",
    "Model informations are written in Github Gist format. The parameters are saved in a `.caffemodel` file specified in the gist. To download the model :\n",
    "\n",
    "```\n",
    "./scripts/download_model_from_gist.sh <gist_id>\n",
    "./scripts/download_model_binary.py <dirname>\n",
    "```\n",
    "\n",
    "where is the gist directory (by default the gist is saved in the **models** directory).\n",
    "\n",
    "Let’s download the CaffeNet model and the labels corresponding to the classes:\n",
    "\n",
    "```\n",
    "./scripts/download_model_binary.py models/bvlc_reference_caffenet\n",
    "./data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "\n",
    "#have a look at the model\n",
    "python python/draw_net.py models/bvlc_reference_caffenet/deploy.prototxt caffenet.png\n",
    "open caffenet.png\n",
    "```\n",
    "\n",
    "\n",
    "This model has been trained on processed images, so you need to preprocess the image with a preprocessor, before saving it in the blob.\n",
    "\n",
    "That is, in the python shell:\n",
    "```python\n",
    "#load the model\n",
    "net = caffe.Net('models/bvlc_reference_caffenet/deploy.prototxt',\n",
    "                'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel',\n",
    "                caffe.TEST)\n",
    "\n",
    "# load input and configure preprocessing\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_mean('data', np.load('python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1))\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "transformer.set_raw_scale('data', 255.0)\n",
    "\n",
    "#note we can change the batch size on-the-fly\n",
    "#since we classify only one image, we change batch size from 10 to 1\n",
    "net.blobs['data'].reshape(1,3,227,227)\n",
    "\n",
    "#load the image in the data layer\n",
    "im = caffe.io.load_image('examples/images/cat.jpg')\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', im)\n",
    "\n",
    "#compute\n",
    "out = net.forward()\n",
    "\n",
    "# other possibility : out = net.forward_all(data=np.asarray([transformer.preprocess('data', im)]))\n",
    "\n",
    "#predicted predicted class\n",
    "print out['prob'].argmax()\n",
    "\n",
    "#print predicted labels\n",
    "labels = np.loadtxt(\"data/ilsvrc12/synset_words.txt\", str, delimiter='\\t')\n",
    "top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]\n",
    "print labels[top_k]\n",
    "```\n",
    "It will print you the top classes detected for the images.\n",
    "\n",
    "Go further : Create a classification map with net surgery to insert a trained model into an extended model where convolutions will be innerproducts spatially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn : solve the params on training data\n",
    "It is now time to create your own model, and training the parameters on training data.\n",
    "\n",
    "To train a network, you need\n",
    "\n",
    "its model definition, as seen previously\n",
    "\n",
    "a second protobuf file, the solver file, describing the parameters for the stochastic gradient.\n",
    "\n",
    "For example, the CaffeNet solver :\n",
    "\n",
    "```\n",
    "net: \"models/bvlc_reference_caffenet/train_val.prototxt\"\n",
    "test_iter: 1000\n",
    "test_interval: 1000\n",
    "base_lr: 0.01\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "stepsize: 100000\n",
    "display: 20\n",
    "max_iter: 450000\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "snapshot: 10000\n",
    "snapshot_prefix: \"models/bvlc_reference_caffenet/caffenet_train\"\n",
    "solver_mode: GPU\n",
    "```\n",
    "\n",
    "Usually, you define a train net, for training, with training data, and a test set, for validation. Either you can define the train and test nets in the prototxt solver file:\n",
    "```\n",
    "train_net: \"examples/hdf5_classification/nonlinear_auto_train.prototxt\"\n",
    "test_net: \"examples/hdf5_classification/nonlinear_auto_test.prototxt\"\n",
    "```\n",
    "or you can also specify only one prototxt file, adding an include phase statement for the layers that have to be different in training and testing phases, such as input data :\n",
    "\n",
    "```\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"examples/imagenet/ilsvrc12_train_lmdb\"\n",
    "    batch_size: 256\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"examples/imagenet/ilsvrc12_val_lmdb\"\n",
    "    batch_size: 50\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be continued ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
