{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueral RGB->D Paper Code Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. mGPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `mGPU=True`, call the function `warp_img_feats_mgpu()` and `_back_warp_homo_parallel_v1()`, defined in `~/mvs-depth/src/baselines/neuralrgbd/code/warping/homography.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img_feats_mgpu(feat_img_src, d_candi, R,t, IntM_tensors, unit_ray_arrays_2D ):\n",
    "    r'''\n",
    "    Warp the feat_imgs_src to the reference view for all candidate depths\n",
    "    Inputs:\n",
    "        feat_img_src - list of source image features: each is NCHW format\n",
    "        d_candi,\n",
    "        R,t - list of rotation and transitions\n",
    "\n",
    "    Output: \n",
    "    Feat_warped_src\n",
    "    '''\n",
    "\n",
    "    IntM_tensor = IntM_tensors.squeeze(0)\n",
    "    P_ref_cuda = unit_ray_arrays_2D.squeeze(0)\n",
    "\n",
    "    d_candi_cuda = torch.from_numpy(d_candi.astype(np.float32)).cuda()\n",
    "\n",
    "    if isinstance(R, list) and isinstance(t, list):\n",
    "        H, W, D = feat_img_src[0].shape[2], feat_img_src[0].shape[3], len(d_candi)\n",
    "        Feat_warped_src = []\n",
    "        for idx_view, feat_img_src_view in enumerate(feat_img_src):\n",
    "            # Get term1 #\n",
    "            term1 = IntM_tensor.matmul(t[idx_view]).unsqueeze(1)\n",
    "            # Get term2 # \n",
    "            term2 = IntM_tensor.matmul(R[idx_view]).matmul(P_ref_cuda)\n",
    "            \n",
    "            feat_img_src_view_repeat = feat_img_src_view.repeat(len(d_candi), 1, 1, 1)\n",
    "\n",
    "            feat_img_src_view_warp_par_d =  _back_warp_homo_parallel_v1(\n",
    "                feat_img_src_view_repeat, \n",
    "                d_candi_cuda, \n",
    "                term1, \n",
    "                term2, \n",
    "                IntM_tensor, \n",
    "                H, \n",
    "                W) \n",
    "\n",
    "            Feat_warped_src.append(\n",
    "                torch.transpose(feat_img_src_view_warp_par_d, dim0=0, dim1=1)\n",
    "                )\n",
    "    else: # added by CCJ;\n",
    "        raise Exception(\"no implemented Error! R and t should be 'list' variables\")\n",
    "    \"\"\"\n",
    "    else:\n",
    "        #NOTE:added by CCJ: this code seems not to be used !!!\n",
    "        H, W, D = feat_img_src.shape[2], feat_img_src.shape[3], len(d_candi)\n",
    "        feat_img_src_view = feat_img_src\n",
    "        # Get term1 #\n",
    "#        term1 = IntM_tensor.matmul(t).reshape(3,1)\n",
    "        term1 = IntM_tensor.matmul(t).unsqueeze(1)\n",
    "        # Get term2 #\n",
    "        term2 = IntM_tensor.matmul(R).matmul(P_ref_cuda)\n",
    "        \n",
    "        feat_img_src_view_repeat = feat_img_src_view.repeat(len(d_candi), 1, 1, 1)\n",
    "        feat_img_src_view_warp_par_d = \\\n",
    "                _back_warp_homo_parallel(feat_img_src_view_repeat,\n",
    "                                         d_candi_cuda, term1, term2,\n",
    "                                         cam_intrinsic, H, W)\n",
    "\n",
    "        Feat_warped_src = torch.transpose(feat_img_src_view_warp_par_d, dim0=0, dim1=1 )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _back_warp_homo_parallel_v1(img_src, D, term1, term2, intrin_M, H, W, debug_inputs = None ):\n",
    "    r'''\n",
    "    Do the warpping for the src. view analytically using homography, given the\n",
    "    depth d for the reference view: \n",
    "    p_src ~ term1  + term2 * d\n",
    "\n",
    "    inputs:\n",
    "    term1, term2 - 3 x n_pix matrix \n",
    "    P_ref - The 2D matrix form for the unit_array for the camera\n",
    "    D - candidate depths. A tensor array on GPU\n",
    "\n",
    "    img_src_warpped - warpped src. image \n",
    "    '''\n",
    "    n_d = len(D)\n",
    "    term2_cp = term2.repeat(n_d, 1, 1)\n",
    "\n",
    "    P_src = term1.unsqueeze(0) + term2_cp * D.reshape(n_d,1,1)\n",
    "    P_src = P_src / (P_src[:, 2, :].unsqueeze(1)  + 1e-10 ) \n",
    "\n",
    "    src_coords = torch.FloatTensor(n_d, H, W, 2).cuda()\n",
    "\n",
    "    src_coords[:,:,:,0] = P_src[:, 0, :].reshape(n_d, H, W)\n",
    "    src_coords[:,:,:,1] = P_src[:, 1, :].reshape(n_d, H, W)\n",
    "    u_center, v_center  = intrin_M[0,2], intrin_M[1,2]\n",
    "    src_coords[:,:,:,0] = (src_coords[:,:,:,0] - u_center) / u_center\n",
    "    src_coords[:,:,:,1] = (src_coords[:,:,:,1] - v_center) / v_center \n",
    "    img_src_warpped = F.grid_sample(img_src, src_coords, mode='bilinear', padding_mode='zeros', align_corners=True) \n",
    "    return img_src_warpped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. mGPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `mGPU=False`, call the function `warp_img_feats_v3()` and `_back_warp_homo_parallel()`, defined in `~/mvs-depth/src/baselines/neuralrgbd/code/warping/homography.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img_feats_v3(feat_img_src, d_candi, R, t, cam_intrinsic):\n",
    "    r'''\n",
    "    Warp the feat_imgs_src to the reference view for all candidate depths\n",
    "    Inputs:\n",
    "        feat_img_src - list of source image features: each is NCHW format\n",
    "        d_candi,\n",
    "        R,t - list of rotation and transitions\n",
    "        cam_intrinsic \n",
    "\n",
    "    Output: \n",
    "    Feat_warped_src\n",
    "    '''\n",
    "\n",
    "    IntM_tensor = cam_intrinsic['intrinsic_M_cuda'].cuda() # intrinsic matrix 3x3 on GPU\n",
    "    P_ref_cuda = cam_intrinsic['unit_ray_array_2D'].cuda() # unit ray array in matrix form on GPU\n",
    "    d_candi_cuda = torch.from_numpy(d_candi.astype(np.float32)).cuda()\n",
    "\n",
    "    if isinstance(R, list) and isinstance(t, list):\n",
    "        H, W, D = feat_img_src[0].shape[2], feat_img_src[0].shape[3], len(d_candi)\n",
    "        Feat_warped_src = []\n",
    "        for idx_view, feat_img_src_view in enumerate(feat_img_src):\n",
    "            # Get term1 #\n",
    "            term1 = IntM_tensor.matmul(t[idx_view]).unsqueeze(1)\n",
    "            # Get term2 # \n",
    "            term2 = IntM_tensor.matmul(R[idx_view]).matmul(P_ref_cuda) \n",
    "            feat_img_src_view_repeat = feat_img_src_view.repeat(len(d_candi), 1, 1, 1) \n",
    "            feat_img_src_view_warp_par_d =  _back_warp_homo_parallel(\n",
    "                feat_img_src_view_repeat, \n",
    "                d_candi_cuda, \n",
    "                term1, term2, \n",
    "                cam_intrinsic, H, W)\n",
    "            Feat_warped_src.append( torch.transpose(feat_img_src_view_warp_par_d, dim0=0, dim1=1 ))\n",
    "\n",
    "    else:\n",
    "        H, W, D = feat_img_src.shape[2], feat_img_src.shape[3], len(d_candi)\n",
    "        feat_img_src_view = feat_img_src\n",
    "\n",
    "        # Get term1 #\n",
    "        term1 = IntM_tensor.matmul(t).unsqueeze(1)\n",
    "\n",
    "        # Get term2 #\n",
    "        term2 = IntM_tensor.matmul(R).matmul(P_ref_cuda)\n",
    "        \n",
    "        feat_img_src_view_repeat = feat_img_src_view.repeat(len(d_candi), 1, 1, 1)\n",
    "        feat_img_src_view_warp_par_d = _back_warp_homo_parallel(feat_img_src_view_repeat,\n",
    "                                                                d_candi_cuda, term1, term2,\n",
    "                                                                cam_intrinsic, H, W)\n",
    "\n",
    "        Feat_warped_src = torch.transpose(feat_img_src_view_warp_par_d, dim0=0, dim1=1 )\n",
    "\n",
    "    return Feat_warped_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _back_warp_homo_parallel(img_src, D, term1, term2, cam_intrinsics, H, W, debug_inputs = None ):\n",
    "    r'''\n",
    "    Do the warpping for the src. view analytically using homography, given the\n",
    "    depth d for the reference view: \n",
    "    p_src ~ term1  + term2 * d\n",
    "\n",
    "    inputs:\n",
    "    term1, term2 - 3 x n_pix matrix \n",
    "    P_ref - The 2D matrix form for the unit_array for the camera\n",
    "    D - candidate depths. A tensor array on GPU\n",
    "\n",
    "    img_src_warpped - warpped src. image \n",
    "    '''\n",
    "    n_d = len(D)\n",
    "    term2_cp = term2.repeat(n_d, 1, 1)\n",
    "\n",
    "    P_src = term1.unsqueeze(0) + term2_cp * D.reshape(n_d,1,1)\n",
    "    P_src = P_src / (P_src[:, 2, :].unsqueeze(1)  + 1e-10 ) \n",
    "\n",
    "    src_coords = torch.FloatTensor(n_d, H, W, 2).cuda()\n",
    "\n",
    "    src_coords[:,:,:,0] = P_src[:, 0, :].reshape(n_d, H, W)\n",
    "    src_coords[:,:,:,1] = P_src[:, 1, :].reshape(n_d, H, W)\n",
    "    u_center, v_center = cam_intrinsics['intrinsic_M'][0,2], cam_intrinsics['intrinsic_M'][1,2]\n",
    "    src_coords[:,:,:,0] = (src_coords[:,:,:,0] - u_center) / u_center\n",
    "    src_coords[:,:,:,1] = (src_coords[:,:,:,1] - v_center) / v_center \n",
    "    img_src_warpped = F.grid_sample(img_src, src_coords, mode='bilinear', padding_mode='zeros', align_corners=True) \n",
    "    return img_src_warpped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
