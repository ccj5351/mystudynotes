{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3415fe5d-096a-4da8-a8bf-55d93bf6e6ea",
   "metadata": {},
   "source": [
    "# Depth and Surface Normal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f2d1d-62ab-4330-910a-c31aa4707c58",
   "metadata": {},
   "source": [
    "## Estimating Depth\n",
    "> D. Eigen, C. Puhrsch, and R. Fergus. Depth map prediction from a single image using a multi-scale deep network. NIPS 2014  \n",
    "\n",
    "\n",
    "## Monocular Depth Estimation\n",
    "\n",
    "### Scale ambiguity\n",
    "\n",
    "<div  align=\"center\">\n",
    "    <img src=\"../files/scale-ambiguity.png\" alt=\"Scale ambiguity\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "### Scale invariant error function\n",
    "\n",
    "Here $y$ and $y^{*}$ for predicted depth and the ground truth depth, respectively.\n",
    "\n",
    "- Loss function definition:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&D\\left(y, y^{*}\\right)=\\frac{1}{2 n} \\sum_{i=1}^{n}\\left(\\log y_{i}-\\log y_{i}^{*}+\\alpha\\left(y_{i}, y_{i}^{*}\\right)\\right)^{2} \\\\\n",
    "&\\alpha\\left(y_{i}, y_{i}^{*}\\right)=\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\log y_{i}^{*}-\\log y_{i}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Why scale invariant? If we can verify $D\\left(a y, a y^{*}\\right)=D\\left(y, y^{*}\\right)$, then it is called \"scale invariant\"!!!\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&D\\left(a y, a y^{*}\\right)=\\frac{1}{2 n} \\sum_{i=1}^{n}\\left(\\log a y_{i}-\\log a y_{i}^{*}+\\alpha\\left(a y_{i}, a y_{i}^{*}\\right)\\right)^{2} \\\\\n",
    "&D\\left(a y, a y^{*}\\right)=\\frac{1}{2 n} \\sum_{i=1}^{n}\\left(\\log a-\\log a+\\log y_{i}-\\log y_{i}^{*}+\\alpha\\left(a y_{i}, a y_{i}^{*}\\right)\\right)^{2} \\\\\n",
    "&D\\left(a y, a y^{*}\\right)=\\frac{1}{2 n} \\sum_{i=1}^{n}\\left(\\log y_{i}-\\log y_{i}^{*}+\\log a-\\log a+\\alpha\\left(y_{i}, y_{i}^{*}\\right)\\right)^{2} \\\\\n",
    "&D\\left(a y, a y^{*}\\right)=D\\left(y, y^{*}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Estimating Surface Normals\n",
    "\n",
    "> X. Wang, D. F. Fouhey, and A. Gupta. Designing deep networks for surface normal estimation. CVPR 2015  \n",
    "> Xiaojuan Qi, et al, GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation, CVPR, 2018   \n",
    "> David F. Fouhey et al, Data-Driven 3D Primitives for Single Image Understanding, ICCV, 2013  \n",
    "\n",
    "### How to represent normals\n",
    "- Normals lie in continuous space\n",
    "- Regression as Classification\n",
    "- Surface normal triangular coding\n",
    "- Delaunay Triangulation cover\n",
    "\n",
    "\n",
    "<div  align=\"center\">\n",
    "    <img src=\"../files/delaunay-triangulation-cover-01.png\" alt=\"drawing\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "- Triangles as classes\n",
    "- Represent Surface Normals\n",
    "- Weighted sum of triangle corners\n",
    "- Loss Function\n",
    "$$\n",
    "L(I, Y)=-\\sum_{i=1}^{M \\times M} \\sum_{k=1}^{K}\\left(1\\left(y_{i}=k\\right) \\log F_{i, k}(I)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20e265-a0a1-461d-8058-20e444dec569",
   "metadata": {},
   "source": [
    "## Depth to Surface Normal\n",
    "\n",
    "> see: [Calculate surface normals from depth image using neighboring pixels cross product](https://stackoverflow.com/questions/34644101/calculate-surface-normals-from-depth-image-using-neighboring-pixels-cross-produc)  \n",
    "> see: [GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation](https://xjqi.github.io/geonet.pdf)  \n",
    "> see: [Data-Driven 3D Primitives for Single Image Understanding](http://www.cs.cmu.edu/~dfouhey/3DP/dfouhey_primitives.pdf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01bb003-a904-4434-87d5-edb2b2416451",
   "metadata": {},
   "source": [
    "### C++ Code:\n",
    "\n",
    "```cpp\n",
    "Mat depth = <my_depth_image> of type CV_32FC1\n",
    "Mat normals(depth.size(), CV_32FC3);\n",
    "\n",
    "for(int x = 0; x < depth.rows; ++x)\n",
    "{\n",
    "    for(int y = 0; y < depth.cols; ++y)\n",
    "    {\n",
    "\n",
    "        float dzdx = (depth.at<float>(x+1, y) - depth.at<float>(x-1, y)) / 2.0;\n",
    "        float dzdy = (depth.at<float>(x, y+1) - depth.at<float>(x, y-1)) / 2.0;\n",
    "\n",
    "        Vec3f d(-dzdx, -dzdy, 1.0f);\n",
    "        Vec3f n = normalize(d);\n",
    "\n",
    "        normals.at<Vec3f>(x, y) = n;\n",
    "    }\n",
    "}\n",
    "\n",
    "imshow(\"depth\", depth / 255);\n",
    "imshow(\"normals\", normals);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247e783-3cac-4f54-8d75-c5b273751e79",
   "metadata": {},
   "source": [
    "### Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccdbc9-1d51-49db-b480-30c10e9bf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
