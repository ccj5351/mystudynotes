{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Practical Introduction to Deep Learning with Caffe and Python (Copied)  \n",
    "\n",
    "> see http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/ for the blog;  \n",
    "> see https://github.com/adilmoujahid/deeplearning-cats-dogs-tutorial for source code;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Caffe Overview\n",
    "\n",
    "Caffe is a deep learning framework developed by the Berkeley Vision and Learning Center (BVLC). It is written in C++ and has Python and Matlab bindings.\n",
    "\n",
    "There are 4 steps in training a CNN using Caffe:\n",
    "\n",
    "- Step 1 - Data preparation: In this step, we clean the images and store them in a format that can be used by Caffe. We will write a Python script that will handle both image pre-processing and storage.\n",
    "- Step 2 - Model definition: In this step, we choose a CNN architecture and we define its parameters in a configuration file with extension .prototxt.\n",
    "- Step 3 - Solver definition: The solver is responsible for model optimization. We define the solver parameters in a configuration file with extension .prototxt.\n",
    "- Step 4 - Model training: We train the model by executing one Caffe command from the terminal. After training the model, we will get the trained model in a file with extension .caffemodel.\n",
    "\n",
    "After the training phase, we will use the `.caffemodel` trained model to make predictions of new unseen data. We will write a Python script to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "we run `create_lmdb.py`:\n",
    "\n",
    "```\n",
    "cd ~/deeplearning-cats-dogs-tutorial/code\n",
    "python create_lmdb.py\n",
    "```\n",
    "\n",
    "create_lmdb.py script does the following:\n",
    "\n",
    "- Run histogram equalization on all training images. Histogram equalization is a technique for adjusting the contrast of images.\n",
    "- Resize all training images to a 227x227 format.\n",
    "- Divide the training data into 2 sets: One for training (5/6 of images) and the other for validation (1/6 of images). The training set is used to train the model, and the validation set is used to calculate the accuracy of the model.\n",
    "- Store the training and validation in 2 LMDB databases. train_lmdb for training the model and validation_lmbd for model evaluation.\n",
    "\n",
    "Below is the explanation of the most important parts of the code:\n",
    "```\n",
    "def transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT):\n",
    "\n",
    "    #Histogram Equalization\n",
    "    img[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n",
    "    img[:, :, 1] = cv2.equalizeHist(img[:, :, 1])\n",
    "    img[:, :, 2] = cv2.equalizeHist(img[:, :, 2])\n",
    "\n",
    "    #Image Resizing\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n",
    "    return img\n",
    "    \n",
    "```\n",
    "\n",
    "See the complete source code in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train_lmdb\n",
      "\n",
      "Creating validation_lmdb\n",
      "\n",
      "Finished processing all images\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Title           :create_lmdb.py\n",
    "Description     :This script divides the training images into 2 sets and stores them in lmdb databases for training and validation.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "import lmdb\n",
    "\n",
    "#Size of images\n",
    "IMAGE_WIDTH = 227\n",
    "IMAGE_HEIGHT = 227\n",
    "\n",
    "def transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT):\n",
    "\n",
    "    #Histogram Equalization\n",
    "    img[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n",
    "    img[:, :, 1] = cv2.equalizeHist(img[:, :, 1])\n",
    "    img[:, :, 2] = cv2.equalizeHist(img[:, :, 2])\n",
    "\n",
    "    #Image Resizing\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "\n",
    "def make_datum(img, label):\n",
    "    #image is numpy.ndarray format. BGR instead of RGB\n",
    "    return caffe_pb2.Datum(\n",
    "        channels=3,\n",
    "        width=IMAGE_WIDTH,\n",
    "        height=IMAGE_HEIGHT,\n",
    "        label=label,\n",
    "        data=np.rollaxis(img, 2).tostring())\n",
    "\n",
    "\n",
    "data_root = \"/media/ccjData2/datasets/kaggle/dogs-vs-cats/\"\n",
    "train_lmdb = data_root + 'train_lmdb'\n",
    "validation_lmdb = data_root + 'validation_lmdb'\n",
    "os.system('rm -r ' + train_lmdb)\n",
    "os.system('rm -r ' + validation_lmdb)\n",
    "train_data = [img for img in glob.glob( data_root + \"train/*jpg\")]\n",
    "test_data = [img for img in glob.glob( data_root + \"test1/*jpg\")]\n",
    "\n",
    "#Shuffle train_data\n",
    "random.shuffle(train_data)\n",
    "\n",
    "print 'Creating train_lmdb'\n",
    "\n",
    "in_db = lmdb.open(train_lmdb, map_size=int(1e12))\n",
    "with in_db.begin(write=True) as in_txn:\n",
    "    for in_idx, img_path in enumerate(train_data):\n",
    "        if in_idx %  6 == 0:\n",
    "            continue\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "        if 'cat' in img_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        datum = make_datum(img, label)\n",
    "        in_txn.put('{:0>5d}'.format(in_idx), datum.SerializeToString())\n",
    "        #print '{:0>5d}'.format(in_idx) + ':' + img_path\n",
    "in_db.close()\n",
    "\n",
    "\n",
    "print '\\nCreating validation_lmdb'\n",
    "\n",
    "in_db = lmdb.open(validation_lmdb, map_size=int(1e12))\n",
    "with in_db.begin(write=True) as in_txn:\n",
    "    for in_idx, img_path in enumerate(train_data):\n",
    "        if in_idx % 6 != 0:\n",
    "            continue\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "        if 'cat' in img_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        datum = make_datum(img, label)\n",
    "        in_txn.put('{:0>5d}'.format(in_idx), datum.SerializeToString())\n",
    "        #print '{:0>5d}'.format(in_idx) + ':' + img_path\n",
    "in_db.close()\n",
    "\n",
    "print '\\nFinished processing all images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transform_img` takes a colored images as input, does the histogram equalization of the 3 color channels and resize the image.  \n",
    "![example of image transformations applied to one training image](http://adilmoujahid.com/images/image-transform.jpg)  \n",
    "\n",
    "```\n",
    "def make_datum(img, label):\n",
    "\n",
    "    return caffe_pb2.Datum(\n",
    "        channels=3,\n",
    "        width=IMAGE_WIDTH,\n",
    "        height=IMAGE_HEIGHT,\n",
    "        label=label,\n",
    "        data=np.rollaxis(img, 2).tostring())\n",
    "```\n",
    "\n",
    "`make_datum` takes an image and its label and return a [Datum object](https://github.com/BVLC/caffe/wiki/The-Datum-Object) that contains the image and its label.\n",
    "\n",
    "\n",
    "```\n",
    "in_db = lmdb.open(train_lmdb, map_size=int(1e12))\n",
    "with in_db.begin(write=True) as in_txn:\n",
    "    for in_idx, img_path in enumerate(train_data):\n",
    "        if in_idx %  6 == 0:\n",
    "            continue\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "        if 'cat' in img_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        datum = make_datum(img, label)\n",
    "        in_txn.put('{:0>5d}'.format(in_idx), datum.SerializeToString())\n",
    "        print '{:0>5d}'.format(in_idx) + ':' + img_path\n",
    "in_db.close()\n",
    "```\n",
    "\n",
    "The code above takes 5/6 of the training images, transforms and stores them in train_lmdb. The code for storing validation data follows the same structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the mean image of training data:\n",
    "We execute the command below to generate the mean image of training data. We will substract the mean image from each input image to ensure every feature pixel has zero mean. This is a common preprocessing step in supervised machine learning.\n",
    "\n",
    "```\n",
    "cd ~/caffe/build/tools\n",
    "./compute_image_mean -backend=lmdb /media/ccjData2/datasets/kaggle/dogs-vs-cats/train_lmdb /media/ccjData2/datasets/kaggle/dogs-vs-cats/mean.binaryproto\n",
    "```\n",
    "\n",
    "This is the corresponding output:  \n",
    "![get-mean-binaryproto.png](../files/get-mean-binaryproto.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "After deciding on the CNN architecture, we need to define its parameters in a `.prototxt` train_val file. Caffe comes with a few popular CNN models such as Alexnet and GoogleNet. In this tutorial, we will use the `bvlc_reference_caffenet` model which is a replication of AlexNet with a few modifications. Below is a copy of the train_val file that we call `caffenet_train_val_1.prototxt`. If you clone the tutorial git repository as explained above, you should have the same file under `deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/`.\n",
    "\n",
    "We need to make the modifications below to the original bvlc_reference_caffenet prototxt file:\n",
    "- Change the path for input data and mean image: Lines 24, 40 and 51.\n",
    "- Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes.\n",
    "- see the file at this [gist reporsitory](https://gist.github.com/ccj5351/fce8c81e36fd62a7ac235462b589d8c6), and see the visulization via Netscope at [this](https://ethereon.github.io/netscope/#/gist/fce8c81e36fd62a7ac235462b589d8c6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the model architecture by executing the command below.\n",
    "```\n",
    "python ~/caffe/python/draw_net.py ~/seg-depth/src/caffe/caffenet_train_val_1.prototxt ~/Downloads/caffe_model_1.png\n",
    "```\n",
    "The model is shown as below:  \n",
    "![affe_model_1.png](../files/caffe_model_1.png)\n",
    "\n",
    "### Netscope:\n",
    "\n",
    "Netscope is a web-based tool for visualizing neural network architectures (or technically, any directed acyclic graph). It currently supports Caffe's prototxt format. So if this `.prototxt` file is part of a GitHub Gist, we can visualize it by visiting [this URL.](https://ethereon.github.io/netscope/#/gist/fce8c81e36fd62a7ac235462b589d8c6)\n",
    "> Note the URL format is `http://ethereon.github.io/netscope/#/gist/your-gist-id`. The `Gist ID` is the numeric suffix in the Gist's URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solver Definition\n",
    "The solver is responsible for model optimization. We define the solver's parameters in a `.prototxt` file. You can find our solver under deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/ with name solver_1.prototxt. Below is a copy of the same.\n",
    "\n",
    "This solver computes the accuracy of the model using the validation set every 1000 iterations. The optimization process will run for a maximum of 40000 iterations and will take a snapshot of the trained model every 5000 iterations.\n",
    "\n",
    "`base_lr`, `lr_policy`, `gamma`, `momentum` and `weight_decay` are hyperparameters that we need to tune to get a good convergence of the model.\n",
    "\n",
    "I chose `lr_policy: \"step\"` with `stepsize: 2500, base_lr: 0.001` and `gamma: 0.1`. In this configuration, we will start with a learning rate of `0.001`, and we will drop the learning rate by a factor of ten every 2500 iterations.\n",
    "\n",
    "There are different strategies for the optimization process. For a detailed explanation, I recommend Caffe's [solver documentation](http://caffe.berkeleyvision.org/tutorial/solver.html).\n",
    "\n",
    "```\n",
    "net: \"/home/ccj/seg-depth/study_caffe/caffenet_train_val_1.prototxt\"\n",
    "test_iter: 1000\n",
    "test_interval: 1000\n",
    "base_lr: 0.001\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "stepsize: 2500\n",
    "display: 50\n",
    "max_iter: 40000\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "snapshot: 5000\n",
    "snapshot_prefix: \"/home/ccj/seg-depth/logs/caffe_model_1\"\n",
    "solver_mode: GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "After defining the model and the solver, we can start training the model by executing the command below:\n",
    "```\n",
    "~/caffe/build/tools/caffe train --solver ~/seg-depth/study_caffe/solver_1.prototxt 2>&1 | tee ~/seg-depth/logs/caffe_model_1/model_1_train.log\n",
    "```\n",
    "\n",
    "The training logs will be stored under `~/seg-depth/logs/caffe_model_1/model_1_train.log`.\n",
    "\n",
    "During the training process, we need to monitor the `loss` and the model `accuracy`. We can stop the process at anytime by pressing Ctrl+c. Caffe will take a snapshot of the trained model every 5000 iterations, and store them under caffe_model_1 folder.\n",
    "\n",
    "The snapshots have `.caffemodel` extension. For example, 10000 iterations snapshot will be called: caffe_model_1_iter_10000.caffemodel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting the learning curve\n",
    "A learning curve is a plot of the training and test losses as a function of the number of iterations. These plots are very useful to visualize the train/validation losses and validation accuracy.\n",
    "\n",
    "We can see from the learning curve that the model achieved a validation accuracy of 90%, and it stopped improving after 3000 iterations.\n",
    "\n",
    "```\n",
    "python ~/seg-depth/study_caffe/plot_learning_curve.py ~/seg-depth/logs/caffe_model_1/model_1_train.log ~/seg-depth/logs/caffe_model_1/caffe_model_1_learning_curve.png\n",
    "```\n",
    "\n",
    "The result is shown below  \n",
    "![caffe_model_1_learning_curve.png](../files/caffe_model_1_learning_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction on New Data\n",
    "Now that we have a trained model, we can use it to make predictions on new unseen data (images from test1). The Python code for making the predictions is make_predictions_1.py and it's stored under deeplearning-cats-dogs-tutorial/code. The code needs 4 files to run:\n",
    "\n",
    "- Test images: We will use test1 images.\n",
    "- Mean image: The mean image that we computed in section 2 above.\n",
    "- Model architecture file: We'll call this file `caffenet_deploy_1.prototxt`. It's stored under deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1. It's structured in a similar way to caffenet_train_val_1.prototxt, but with a few modifications. We need to delete the data layers, add an input layer and change the last layer type from `SoftmaxWithLoss` to `Softmax`.  \n",
    "- Trained model weights: This is the file that we computed in the training phase. We will use `caffe_model_1_iter_10000.caffemodel`.\n",
    "\n",
    "To run the Python code, we need to execute the command below. The predictions will be stored under deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/submission_model_1.csv.\n",
    "\n",
    "```\n",
    "cd ~/seg-depth/study_caffe\n",
    "python make_predictions_1.py\n",
    "```\n",
    "\n",
    "Below is the explanation of the most important parts in the code.\n",
    "\n",
    "```python\n",
    "#Read mean image\n",
    "mean_blob = caffe_pb2.BlobProto()\n",
    "with open('/home/ubuntu/deeplearning-cats-dogs-tutorial/input/mean.binaryproto') as f:\n",
    "    mean_blob.ParseFromString(f.read())\n",
    "mean_array = np.asarray(mean_blob.data, dtype=np.float32).reshape(\n",
    "    (mean_blob.channels, mean_blob.height, mean_blob.width))\n",
    "\n",
    "\n",
    "#Read model architecture and trained model's weights\n",
    "net = caffe.Net('/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffenet_deploy_1.prototxt',\n",
    "                '/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1_iter_10000.caffemodel',\n",
    "                caffe.TEST)\n",
    "\n",
    "#Define image transformers\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_mean('data', mean_array)\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "```\n",
    "\n",
    "\n",
    "The code above stores the mean image under `mean_array`, defines a model called `net` by reading the deploy file and the trained model, and defines the transformations that we need to apply to the test images.\n",
    "\n",
    "```python\n",
    "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "\n",
    "net.blobs['data'].data[...] = transformer.preprocess('data', img)\n",
    "out = net.forward()\n",
    "pred_probas = out['prob']\n",
    "print pred_probas.argmax()\n",
    "\n",
    "```\n",
    "\n",
    "The code above read an image, apply similar image processing steps to training phase, calculates each class's probability and prints the class with the largest probability (0 for cats, and 1 for dogs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Building a Cat/Dog Classifier using Transfer Learning\n",
    "### 8.1 What is Transfer Learning?\n",
    "\n",
    "Convolutional neural networks require large datasets and a lot of computional time to train. Some networks could take up to 2-3 weeks across multiple GPUs to train. `Transfer learning` is a very useful technique that tries to address both problems. Instead of training the network from scratch, transfer learning utilizes a trained model on a different dataset, and adapts it to the problem that we're trying to solve.\n",
    "\n",
    "There are 2 strategies for transfer learning:\n",
    "\n",
    "- Utilize the trained model as a fixed feature extractor: In this strategy, we remove the last fully connected layer from the trained model, we freeze the weights of the remaining layers, and we train a machine learning classifier (e.g., SVM) on the output of the remaining layers.\n",
    "- Fine-tune the trained model: In this strategy, we fine tune the trained model on the new dataset by `continuing the backpropagation`. We can either fine-tune the whole network or freeze some of its layers.\n",
    "\n",
    "For a detailed explanation of transfer learning, I recommend reading these [cs 231n deep learning course notes.](http://cs231n.github.io/transfer-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Training the Cat/Dog Classifier using Transfer Learning\n",
    "\n",
    "Caffe comes with a repository that is used by researchers and machine learning practitioners to share their trained models. This library is called `Model Zoo`.\n",
    "\n",
    "We will utilize the trained `bvlc_reference_caffenet` as a starting point of building our cat/dog classifier using transfer learning. This model was trained on the ImageNet dataset which contains millions of images across 1000 categories.\n",
    "\n",
    "We will use the fine-tuning strategy for training our model.\n",
    "\n",
    "#### Download trained bvlc_reference_caffenet model (i.e., the trained model weights):\n",
    "\n",
    "We can download the trained model by executing the command below.\n",
    "```\n",
    "cd ~/caffe/models/bvlc_reference_caffenet\n",
    "wget http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel\n",
    "```\n",
    "\n",
    "#### Model Definition\n",
    "The model and solver configuration files are stored under `deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2`. We need to make the following change to the original bvlc_reference_caffenet model configuration file.\n",
    "\n",
    "- Change the path for input data and mean image: Lines 24, 40 and 51.\n",
    "- Change the name of the last fully connected layer from fc8 to fc8-cats-dogs. Lines 360, 363, 387 and 397.\n",
    "- Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes.\n",
    "\n",
    "Note that if we keep a layer's name unchanged and we pass the trained model's weights to Caffe, it will pick its weights from the trained model. If we want to `freeze a layer`, we need to setup its `lr_mult` parameter to `0`.  \n",
    "> see this file at [this gist repository.](https://gist.github.com/ccj5351/5a0e9f65ba42f658924295126f4e1f5f)\n",
    "\n",
    "#### Solver Definition\n",
    "We will use a similar solver to the one used before.\n",
    "> see this file at [this gist repository.](https://gist.github.com/ccj5351/5a0e9f65ba42f658924295126f4e1f5f)\n",
    "\n",
    "#### Model Training with Transfer Learning\n",
    "After defining the model and the solver, we can start training the model by executing the command below. Note that we can pass the trained model's weights by using the argument `--weights`.\n",
    "\n",
    "```\n",
    "~/caffe/build/tools/caffe train --solver /home/ccj/seg-depth/study_caffe/solver_2.prototxt --weights /home/ccj/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel 2>&1 | tee /home/ccj/seg-depth/logs/caffe_model_2/model_2_train.log\n",
    "```\n",
    "\n",
    "#### Plotting the Learning Curve\n",
    "Similarly to the previous section, we can plot the learning curve by executing the command below. We can see from the learning curve that the model achieved an accuracy of `~97%` after 1000 iterations only. This shows the power of `transfer learning`. We were able to get a higher accuracy with a smaller number of iterations.\n",
    "\n",
    "```\n",
    "python ~/seg-depth/study_caffe/plot_learning_curve.py ~/seg-depth/logs/caffe_model_2/model_2_train.log ~/seg-depth/logs/caffe_model_2/caffe_model_2_learning_curve.png\n",
    "```\n",
    "\n",
    "The result is shown as below:  \n",
    "![caffe_model_2_learning_curve.png](../files/caffe_model_2_learning_curve.png)\n",
    "\n",
    "#### Prediction on New Data\n",
    "Similarly, we will generate predictions on the test data and upload the results to Kaggle to get the model accuracy. The code for making the predicitions is under deeplearning-cats-dogs-tutorial/code/make_predictions_2.py.\n",
    "\n",
    "The model got an accuracy of 0.97154 which is better than the model that we trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "In this blog post, we covered core concepts of deep learning and convolutional neural networks. We also learned how to build convolutional neural networks using Caffe and Python from scratch and using transfer learning. If you want to learn more about this topic, I highly recommend Stanford's [\"Convolutional Neural Networks for Visual Recognition\" course](http://cs231n.github.io/).\n",
    "\n",
    "## 10. References\n",
    "1. [CS231n - Neural Networks Part 1: Setting up the Architecture](http://cs231n.github.io/neural-networks-1/)\n",
    "2. [Wikipedia - Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n",
    "3. [CS231n - Transfer Learning Notes](http://cs231n.github.io/transfer-learning/)\n",
    "4. [A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\n",
    "5. [CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
