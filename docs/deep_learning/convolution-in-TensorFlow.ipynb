{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Convolution is implemented in TensorFlow, Caffe or PyTorch?\n",
    "> see  \n",
    "> 1. https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/making_faster.html\n",
    "> 2. https://www.reddit.com/r/MLQuestions/comments/8no4xe/anyone_familiar_with_how_tensorflow_or_pytorch/\n",
    "> 3. https://cs231n.github.io/convolutional-networks/#conv\n",
    "> 4. [tensorflow && caffe conv2D GPU版](https://www.jianshu.com/p/89667d844cac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolution:\n",
    "- Convolution is a mathematical operation that does the integral of the product of 2 functions(signals), with one of the signals flipped. \n",
    "- Equation: \n",
    "\n",
    "$$ \\begin{split} y[n_1, n_2] &= \\sum_{k_1 = -\\infty}^{\\infty} \\sum_{k_2 = -\\infty}^{\\infty} x[k_1, k_2] h [n_1 - k_1, n_2 - k_2] \\\\ \n",
    "&= x[n_1, n_2] * h[n_1, n_2] \\\\\n",
    "&= h[n_1, n_2] * x[n_1, n_2]\n",
    "\\end{split} $$\n",
    "\n",
    "- Procedure:  \n",
    "![Alt text|center|0X250](./files/convolution-procedure.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Convolution in CNN:\n",
    "\n",
    "- CNN vs Neuron:  \n",
    "![Alt text|center](./files/convolution-in-cnn.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## [Making faster convolution via matrix multiplication](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/making_faster.html)\n",
    "\n",
    "Here we show a way to convert your convolution operation into a matrix multiplication. This has the advantage to compute faster, at the `expense of more memory usage`. We employ the `im2col` operation that will transform the input image or batch into a matrix, then we multiply this matrix with a reshaped version of our `kernel`. Then at the end we reshape this multiplied matrix back to an image with the `col2im` operation.\n",
    "\n",
    "As shown on previous source code, we use a lot for for-loops to implement the convolutions, while this is useful for learning purpose, it's not fast enough. On this section we will learn how to implement convolutions on a `vectorized fashion`.\n",
    "\n",
    "First, if we inspect closer the code for convolution is basically a `dot-product` between the kernel filter and the local regions selected by the moving window, that sample a patch with the same size as our kernel.\n",
    "\n",
    "What would happens if we `expand all possible windows` on memory and perform the `dot product` as a matrix multiplication. Answer `200x or more` speedups, at the expense of more `memory consumption`.  \n",
    "\n",
    "![Alt text|center](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/Convolution_With_Im2col.png)\n",
    "\n",
    "For example, if the input is `[227x227x3]` and it is to be convolved with `11x11x3` filters at stride `4` and padding `0`, then we would take `[11x11x3]` blocks of pixels in the input and stretch each block into a `column vector` of size  `11∗11∗3  = 363`.\n",
    "\n",
    "Calculating with input 227 with stride 4 and padding 0, gives `((227-11)/4)+1 = 55` locations along both width and height, leading to an output matrix `X_col` of size `[363 x 3025]`.\n",
    "Here every column is a stretched out `receptive field` (patch with depth) and there are `55*55 = 3025` of them in total.\n",
    "\n",
    "To summarize how we calculate the `im2col` output sizes:\n",
    "\n",
    "```python\n",
    "[img_height, img_width, img_channels] = size(img);\n",
    "newImgHeight = floor(((img_height + 2*P - ksize) / S)+1);\n",
    "newImgWidth = floor(((img_width + 2*P - ksize) / S)+1);        \n",
    "cols = single(zeros((img_channels*ksize*ksize),(newImgHeight * newImgWidth)));\n",
    "```\n",
    "\n",
    "The weights of the CONV layer are similarly stretched out into `rows`. For example, if there are 96 filters of size `[11x11x3]` this would give a matrix `W_row` of size `[96 x 363]`, where `11x11x3=363`  \n",
    "\n",
    "![Alt text|center](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/im2col_operation.png)\n",
    "\n",
    "After the image and the kernel are converted, the convolution can be implemented as a simple matrix multiplication, in our case it will be `W_col[96 x 363] multiplied by X_col[363 x 3025]` resulting as a matrix `[96 x 3025]`, that need to be reshaped back to `[55x55x96]`.\n",
    "\n",
    "This final reshape can also be implemented as a function called `col2im`.\n",
    "\n",
    "Notice that some implementations of `im2col` will have this result transposed, if this is the case then the order of the matrix multiplication must be changed.  \n",
    "\n",
    "![Alt text|center](./files/Im2Col_cs231n.png)\n",
    "\n",
    "\n",
    "## Forward graph\n",
    "In order to help the usage of `im2col` with convolution and also to derive the back-propagation, let's show the convolution with `im2col` as a graph. Here the input tensor is single a 3 channel 4x4 image. That will pass to a convolution layer with `S:1 P:0 K:2 and F:1 (Output volume)`.  \n",
    "\n",
    "![convolution  forward graph|center](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/assets/Conv_Graph_Im2col.png)\n",
    "\n",
    "\n",
    "## Backward graph\n",
    "\n",
    "Using the `im2col` technique the computation graph resembles the `FC` layer with the same format  $f(x, \\theta, \\beta )=(x \\cdot \\theta^T) + \\beta $, the difference that now we have a bunch of reshapes, transposes and the `im2col` block.\n",
    "\n",
    "About the reshapes and transposes during back propagation you just need to `invert` their operations using again another reshape or transpose, the only important thing to remember is that if you use a `reshape row major` during forward propagation you need to use a `reshape row major` on the backpropagation.\n",
    "\n",
    "The only point to pay attention is the `im2col backpropagation` operation. The issue is that it cannot be implemented as a simple reshape. This is because the patches could actually overlap (depending on the stride), so you need to sum the gradients where the patches intersect.  \n",
    "\n",
    "![Alt text|center](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/assets/Conv_Graph_Im2col_Backward.png)\n",
    "\n",
    "\n",
    "## Smaller example:\n",
    "To make things simpler on our heads, follow the simple example of convolving X[3x3] with W[2x2]\n",
    "![Alt text](./1551297448178.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Im2col and Col2im sources in python:\n",
    "This implementation will receive a image on the format of a 3 dimension tensor `[channels, rows, cols]` and will create a 2d matrix on the format `[rows=(new_h*new_w), cols=(kw*kw*C)]` notice that this algorithm will output the transposed version of the diagram above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def im2col(x,hh,ww,stride):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: image matrix to be translated into columns, (C,H,W)\n",
    "      hh: filter height\n",
    "      ww: filter width\n",
    "      stride: stride\n",
    "    Returns:\n",
    "      col: (new_h*new_w,hh*ww*C) matrix, each column is a cube that will convolve with a filter\n",
    "            new_h = (H-hh) // stride + 1, new_w = (W-ww) // stride + 1\n",
    "    \"\"\"\n",
    "\n",
    "    c,h,w = x.shape\n",
    "    new_h = (h-hh) // stride + 1\n",
    "    new_w = (w-ww) // stride + 1\n",
    "    col = np.zeros([new_h*new_w,c*hh*ww])\n",
    "\n",
    "    for i in range(new_h):\n",
    "       for j in range(new_w):\n",
    "           patch = x[...,i*stride:i*stride+hh,j*stride:j*stride+ww]\n",
    "           col[i*new_w+j,:] = np.reshape(patch,-1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(mul,h_prime,w_prime,C):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "      mul: (h_prime*w_prime*w,F) matrix, each col should be reshaped to C*h_prime*w_prime when C>0, or h_prime*w_prime when C = 0\n",
    "      h_prime: reshaped filter height\n",
    "      w_prime: reshaped filter width\n",
    "      C: reshaped filter channel, if 0, reshape the filter to 2D, Otherwise reshape it to 3D\n",
    "    Returns:\n",
    "      if C == 0: (F,h_prime,w_prime) matrix\n",
    "      Otherwise: (F,C,h_prime,w_prime) matrix\n",
    "    \"\"\"\n",
    "    F = mul.shape[1]\n",
    "    if(C == 1):\n",
    "        out = np.zeros([F,h_prime,w_prime])\n",
    "        for i in range(F):\n",
    "            col = mul[:,i]\n",
    "            out[i,:,:] = np.reshape(col,(h_prime,w_prime))\n",
    "    else:\n",
    "        out = np.zeros([F,C,h_prime,w_prime])\n",
    "        for i in range(F):\n",
    "            col = mul[:,i]\n",
    "            out[i,:,:] = np.reshape(col,(C,h_prime,w_prime))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im_back(dim_col,h_prime,w_prime,stride,hh,ww,c):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      dim_col: gradients for im_col,(h_prime*w_prime,hh*ww*c)\n",
    "      h_prime,w_prime: height and width for the feature map\n",
    "      strid: stride\n",
    "      hh,ww,c: size of the filters\n",
    "    Returns:\n",
    "      dx: Gradients for x, (C,H,W)\n",
    "    \"\"\"\n",
    "    H = (h_prime - 1) * stride + hh\n",
    "    W = (w_prime - 1) * stride + ww\n",
    "    dx = np.zeros([c,H,W])\n",
    "    for i in range(h_prime*w_prime):\n",
    "        row = dim_col[i,:]\n",
    "        h_start = (i / w_prime) * stride\n",
    "        w_start = (i % w_prime) * stride\n",
    "        dx[:,h_start:h_start+hh,w_start:w_start+ww] += np.reshape(row,(c,hh,ww))\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python example for forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward_naive(x, w, b, conv_param):\n",
    "  \"\"\"\n",
    "  A naive implementation of the forward pass for a convolutional layer.\n",
    "\n",
    "  The input consists of N data points, each with C channels, height H and width\n",
    "  W. We convolve each input with F different filters, where each filter spans\n",
    "  all C channels and has height HH and width HH.\n",
    "\n",
    "  Input:\n",
    "  - x: Input data of shape (N, C, H, W)\n",
    "  - w: Filter weights of shape (F, C, HH, WW)\n",
    "  - b: Biases, of shape (F,)\n",
    "  - conv_param: A dictionary with the following keys:\n",
    "    - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "      horizontal and vertical directions.\n",
    "    - 'pad': The number of pixels that will be used to zero-pad the input.\n",
    "\n",
    "  Returns a tuple of:\n",
    "  - out: Output data, of shape (N, F, H', W') where H' and W' are given by\n",
    "    H' = 1 + (H + 2 * pad - HH) / stride\n",
    "    W' = 1 + (W + 2 * pad - WW) / stride\n",
    "  - cache: (x, w, b, conv_param)\n",
    "  \"\"\"\n",
    "  out = None\n",
    "  pad_num = conv_param['pad']\n",
    "  stride = conv_param['stride']\n",
    "  N,C,H,W = x.shape\n",
    "  F,C,HH,WW = w.shape\n",
    "  H_prime = (H+2*pad_num-HH) // stride + 1\n",
    "  W_prime = (W+2*pad_num-WW) // stride + 1\n",
    "  out = np.zeros([N,F,H_prime,W_prime])\n",
    "  #im2col\n",
    "  for im_num in range(N):\n",
    "      im = x[im_num,:,:,:]\n",
    "      im_pad = np.pad(im,((0,0),(pad_num,pad_num),(pad_num,pad_num)),'constant')\n",
    "      im_col = im2col(im_pad,HH,WW,stride)\n",
    "      filter_col = np.reshape(w,(F,-1))\n",
    "      mul = im_col.dot(filter_col.T) + b\n",
    "      out[im_num,:,:,:] = col2im(mul,H_prime,W_prime,1)\n",
    "  cache = (x, w, b, conv_param)\n",
    "  return out, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python example for backward propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward_naive(dout, cache):\n",
    "  \"\"\"\n",
    "  A naive implementation of the backward pass for a convolutional layer.\n",
    "\n",
    "  Inputs:\n",
    "  - dout: Upstream derivatives.\n",
    "  - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive\n",
    "\n",
    "  Returns a tuple of:\n",
    "  - dx: Gradient with respect to x\n",
    "  - dw: Gradient with respect to w\n",
    "  - db: Gradient with respect to b\n",
    "  \"\"\"\n",
    "  dx, dw, db = None, None, None\n",
    "\n",
    "  x, w, b, conv_param = cache\n",
    "  pad_num = conv_param['pad']\n",
    "  stride = conv_param['stride']\n",
    "  N,C,H,W = x.shape\n",
    "  F,C,HH,WW = w.shape\n",
    "  H_prime = (H+2*pad_num-HH) // stride + 1\n",
    "  W_prime = (W+2*pad_num-WW) // stride + 1\n",
    "\n",
    "  dw = np.zeros(w.shape)\n",
    "  dx = np.zeros(x.shape)\n",
    "  db = np.zeros(b.shape)\n",
    "\n",
    "  # We could calculate the bias by just summing over the right dimensions\n",
    "  # Bias gradient (Sum on dout dimensions (batch, rows, cols)\n",
    "  #db = np.sum(dout, axis=(0, 2, 3))\n",
    "\n",
    "  for i in range(N):\n",
    "      im = x[i,:,:,:]\n",
    "      im_pad = np.pad(im,((0,0),(pad_num,pad_num),(pad_num,pad_num)),'constant')\n",
    "      im_col = im2col(im_pad,HH,WW,stride)\n",
    "      filter_col = np.reshape(w,(F,-1)).T\n",
    "\n",
    "      dout_i = dout[i,:,:,:]\n",
    "      dbias_sum = np.reshape(dout_i,(F,-1))\n",
    "      dbias_sum = dbias_sum.T\n",
    "\n",
    "      #bias_sum = mul + b\n",
    "      db += np.sum(dbias_sum,axis=0)\n",
    "      dmul = dbias_sum\n",
    "\n",
    "      #mul = im_col * filter_col\n",
    "      dfilter_col = (im_col.T).dot(dmul)\n",
    "      dim_col = dmul.dot(filter_col.T)\n",
    "\n",
    "      dx_padded = col2im_back(dim_col,H_prime,W_prime,stride,HH,WW,C)\n",
    "      dx[i,:,:,:] = dx_padded[:,pad_num:H+pad_num,pad_num:W+pad_num]\n",
    "      dw += np.reshape(dfilter_col.T,(F,C,HH,WW))\n",
    "  return dx, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller example:\n",
    "To make things simpler on our heads, follow the simple example of convolving X[3x3] with W[2x2]  \n",
    "![Alt text](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_4/simple_im2col.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter W =  [[1 3]\n",
      " [2 4]]\n",
      "flipped W =  [[4 2]\n",
      " [3 1]]\n",
      "W_col =  [4 2 3 1]\n",
      "X_col =  [[1. 4. 2. 5.]\n",
      " [4. 7. 5. 8.]\n",
      " [2. 5. 3. 6.]\n",
      " [5. 8. 6. 9.]]\n",
      "conv result =  [23. 53. 33. 63.]\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[1,3], [2,4]])\n",
    "print 'filter W = ', W\n",
    "X = np.array([[[1, 4 ,7], [2, 5, 8], [3, 6,9]]])\n",
    "W = np.flip(np.flip(W, axis = 0), axis = 1)\n",
    "print 'flipped W = ', W\n",
    "W_col = W.flatten()\n",
    "print 'W_col = ', W_col\n",
    "X_col = im2col(X, hh = 2, ww = 2, stride = 1)\n",
    "print 'X_col = ', X_col\n",
    "conv = X_col.dot(W_col.T)\n",
    "print 'conv result = ', conv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
